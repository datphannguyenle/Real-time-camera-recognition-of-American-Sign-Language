{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpCFkFaa3A6z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import cv2\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras import models, layers, optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image as image_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "# Dinh nghia cac bien\n",
        "\n",
        "gestures = {'L_': 'L',\n",
        "           'fi': 'E',\n",
        "           'ok': 'F',\n",
        "           'pe': 'V',\n",
        "           'pa': 'B'\n",
        "            }\n",
        "\n",
        "gestures_map = {'E': 0,\n",
        "                'L': 1,\n",
        "                'F': 2,\n",
        "                'V': 3,\n",
        "                'B': 4\n",
        "                }\n",
        "\n",
        "\n",
        "gesture_names = {0: 'E',\n",
        "                 1: 'L',\n",
        "                 2: 'F',\n",
        "                 3: 'V',\n",
        "                 4: 'B'}\n",
        "\n",
        "image_path = '/content/drive/MyDrive/data'\n",
        "models_path = '/content/drive/MyDrive/models/saved_model.hdf5'\n",
        "rgb = False\n",
        "imageSize = 224\n",
        "\n",
        "\n",
        "# Ham xu ly anh resize ve 224x224 va chuyen ve numpy array\n",
        "def process_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((imageSize, imageSize))\n",
        "    img = np.array(img)\n",
        "    return img\n",
        "\n",
        "# Xu ly du lieu dau vao\n",
        "def process_data(X_data, y_data):\n",
        "    X_data = np.array(X_data, dtype = 'float32')\n",
        "    if rgb:\n",
        "        pass\n",
        "    else:\n",
        "        X_data = np.stack((X_data,)*3, axis=-1)\n",
        "    X_data /= 255\n",
        "    y_data = np.array(y_data)\n",
        "    y_data = to_categorical(y_data)\n",
        "    return X_data, y_data\n",
        "\n",
        "# Ham duuyet thu muc anh dung de train\n",
        "def walk_file_tree(image_path):\n",
        "    X_data = []\n",
        "    y_data = []\n",
        "    for directory, subdirectories, files in os.walk(image_path):\n",
        "        for file in files:\n",
        "            if not file.startswith('.'):\n",
        "                path = os.path.join(directory, file)\n",
        "                gesture_name = gestures[file[0:2]]\n",
        "                print(gesture_name)\n",
        "                print(gestures_map[gesture_name])\n",
        "                y_data.append(gestures_map[gesture_name])\n",
        "                X_data.append(process_image(path))\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    X_data, y_data = process_data(X_data, y_data)\n",
        "    return X_data, y_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load du lieu vao X va Y\n",
        "X_data, y_data = walk_file_tree(image_path)\n",
        "\n",
        "# Phan chia du lieu train va test theo ty le 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state=12, stratify=y_data)\n",
        "\n",
        "# Dat cac checkpoint de luu lai model tot nhat\n",
        "model_checkpoint = ModelCheckpoint(filepath=models_path, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_acc',\n",
        "                               min_delta=0,\n",
        "                               patience=10,\n",
        "                               verbose=1,\n",
        "                               mode='auto',\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "# Khoi tao model\n",
        "model1 = VGG16(weights='imagenet', include_top=False, input_shape=(imageSize, imageSize, 3))\n",
        "optimizer1 = optimizers.Adam()\n",
        "base_model = model1\n",
        "\n",
        "# Them cac lop ben tren\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu', name='fc1')(x)\n",
        "x = Dense(128, activation='relu', name='fc2')(x)\n",
        "x = Dense(128, activation='relu', name='fc2a')(x)\n",
        "x = Dense(128, activation='relu', name='fc3')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu', name='fc4')(x)\n",
        "\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Dong bang cac lop duoi, chi train lop ben tren minh them vao\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Luu model da train ra file\n",
        "model.save('/content/drive/MyDrive/models/mymodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import copy\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import time\n",
        "\n",
        "# Cac khai bao bien\n",
        "prediction = ''\n",
        "score = 0\n",
        "bgModel = None\n",
        "\n",
        "gesture_names = {0: 'E',\n",
        "                 1: 'L',\n",
        "                 2: 'F',\n",
        "                 3: 'V',\n",
        "                 4: 'B'}\n",
        "\n",
        "# Load model tu file da train\n",
        "model = load_model('models/mymodel.h5')\n",
        "\n",
        "# Ham de predict xem la ky tu gi\n",
        "def predict_rgb_image_vgg(image):\n",
        "    image = np.array(image, dtype='float32')\n",
        "    image /= 255\n",
        "    pred_array = model.predict(image)\n",
        "    print(f'pred_array: {pred_array}')\n",
        "    result = gesture_names[np.argmax(pred_array)]\n",
        "    print(f'Result: {result}')\n",
        "    print(max(pred_array[0]))\n",
        "    score = float(\"%0.2f\" % (max(pred_array[0]) * 100))\n",
        "    print(result)\n",
        "    return result, score\n",
        "\n",
        "\n",
        "# Ham xoa nen khoi anh\n",
        "def remove_background(frame):\n",
        "    fgmask = bgModel.apply(frame, learningRate=learningRate)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
        "    res = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
        "    return res\n",
        "\n",
        "\n",
        "# Khai bao kich thuoc vung detection region\n",
        "cap_region_x_begin = 0.5\n",
        "cap_region_y_end = 0.8\n",
        "\n",
        "# Cac thong so lay threshold\n",
        "threshold = 60\n",
        "blurValue = 41\n",
        "bgSubThreshold = 50#50\n",
        "learningRate = 0\n",
        "\n",
        "# Nguong du doan ky tu\n",
        "predThreshold= 95\n",
        "\n",
        "isBgCaptured = 0  # Bien luu tru da capture background chua\n",
        "\n",
        "# Camera\n",
        "camera = cv2.VideoCapture(0)\n",
        "camera.set(10,200)\n",
        "camera.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.01)\n",
        "\n",
        "while camera.isOpened():\n",
        "    # Doc anh tu webcam\n",
        "    ret, frame = camera.read()\n",
        "    # Lam min anh\n",
        "    frame = cv2.bilateralFilter(frame, 5, 50, 100)\n",
        "    # Lat ngang anh\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Ve khung hinh chu nhat vung detection region\n",
        "    cv2.rectangle(frame, (int(cap_region_x_begin * frame.shape[1]), 0),\n",
        "                  (frame.shape[1], int(cap_region_y_end * frame.shape[0])), (255, 0, 0), 2)\n",
        "\n",
        "    # Neu ca capture dc nen\n",
        "    if isBgCaptured == 1:\n",
        "        # Tach nen\n",
        "        img = remove_background(frame)\n",
        "\n",
        "        # Lay vung detection\n",
        "        img = img[0:int(cap_region_y_end * frame.shape[0]),\n",
        "              int(cap_region_x_begin * frame.shape[1]):frame.shape[1]]  # clip the ROI\n",
        "\n",
        "\n",
        "\n",
        "        # Chuyen ve den trang\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)\n",
        "\n",
        "        cv2.imshow('original1', cv2.resize(blur, dsize=None, fx=0.5, fy=0.5))\n",
        "\n",
        "        ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        cv2.imshow('thresh', cv2.resize(thresh, dsize=None, fx=0.5, fy=0.5))\n",
        "\n",
        "        if (np.count_nonzero(thresh)/(thresh.shape[0]*thresh.shape[0])>0.2):\n",
        "            # Neu nhu ve duoc hinh ban tay\n",
        "            if (thresh is not None):\n",
        "                # Dua vao mang de predict\n",
        "                target = np.stack((thresh,) * 3, axis=-1)\n",
        "                target = cv2.resize(target, (224, 224))\n",
        "                target = target.reshape(1, 224, 224, 3)\n",
        "                prediction, score = predict_rgb_image_vgg(target)\n",
        "\n",
        "                # Neu probality > nguong du doan thi hien thi\n",
        "                print(score,prediction)\n",
        "                if (score>=predThreshold):\n",
        "                    cv2.putText(frame, \"Sign:\" + prediction, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 3,\n",
        "                                (0, 0, 255), 10, lineType=cv2.LINE_AA)\n",
        "    thresh = None\n",
        "\n",
        "    # Xu ly phim bam\n",
        "    k = cv2.waitKey(10)\n",
        "    if k == ord('q'):  # Bam q de thoat\n",
        "        break\n",
        "    elif k == ord('b'):\n",
        "        bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)\n",
        "\n",
        "        isBgCaptured = 1\n",
        "        cv2.putText(frame, \"Background captured\", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 3,\n",
        "                    (0, 0, 255), 10, lineType=cv2.LINE_AA)\n",
        "        time.sleep(2)\n",
        "        print('Background captured')\n",
        "\n",
        "    elif k == ord('r'):\n",
        "\n",
        "        bgModel = None\n",
        "        isBgCaptured = 0\n",
        "        cv2.putText(frame, \"Background reset\", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 3,\n",
        "                    (0, 0, 255),10,lineType=cv2.LINE_AA)\n",
        "        print('Background reset')\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "    cv2.imshow('original', cv2.resize(frame, dsize=None, fx=0.5, fy=0.5))\n",
        "\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "camera.release()"
      ],
      "metadata": {
        "id": "q0GMQJQ3wBSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}